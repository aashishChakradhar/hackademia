{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Natural Language Processing - NLP</h1>\n",
    "<p>Branch of AI that focuses on the interaction between computers and human languages</p>\n",
    "<p>Includes the ability of a computer to understand, interpret, and generate human language in a valuable way</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Common application:</h3>\n",
    "<ul>\n",
    "    <li>Text Classification: Spam detection, sentiment analysis</li>\n",
    "    <li>Machine Translation</li>\n",
    "    <li>Named Entity Recognition</li>\n",
    "    <li>Speech Recognition</li>\n",
    "    <li>Chatbots</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Installing Packages</h2>\n",
    "<p>NLTK and Spacy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: spacy in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (72.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aashish/Desktop/vsCode/hackmedia/python/python_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk\n",
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic text processing techiniques</h2>\n",
    "<h3>Tokenization</h3>\n",
    "<p>Tokenization is the process of breaking down text into individual units, such as words or sentences.</p>\n",
    "<p>Used to remove unnecessary words for faster performance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing spacy and a method 'download' from spacy.cli\n",
    "import spacy\n",
    "from spacy.cli import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_core_web_sm = English core from web small \n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Model not found\")\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural language processing with python is fun. let's tokenize this sentence\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing with python is fun.', \"let's tokenize this sentence\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = [sent.text for sent in doc.sents]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'with', 'python', 'is', 'fun', '.', 'let', \"'s\", 'tokenize', 'this', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "word = [token.text for token in doc]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'with', 'python', 'is', 'fun.', \"let's\", 'tokenize', 'this', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "print(text.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing with python is fun', \" let's tokenize this sentence\"]\n"
     ]
    }
   ],
   "source": [
    "print(text.split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stems: ['run', 'run', 'runner', 'easili', 'fairli']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = ['running','run','runner','easily','fairly']\n",
    "\n",
    "stems = [ps.stem(word) for word in words]\n",
    "print('stems:',stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas: ['they', 'be', 'crazy']\n"
     ]
    }
   ],
   "source": [
    "import spacy_loggers\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# text = 'Natural Language Processing with Python is fun. Let\\'s tokenize this sentence!'\n",
    "# text = \"He's crazy.\"\n",
    "text = \"they are crazy\"\n",
    "doc = nlp(text)\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print('Lemas:',lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import  fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "categories = ['rec.autos', \n",
    "                'sci.electronics', \n",
    "                'comp.graphics', \n",
    "                'rec.sport.hockey',\n",
    "                'talk.politics.guns',\n",
    "                'talk.politics.mideast',\n",
    "                'comp.os.ms-windows.misc',\n",
    "                'comp.sys.ibm.pc.hardware',\n",
    "                'misc.forsale',\n",
    "                'sci.med'\n",
    "]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset = 'train',categories = categories)\n",
    "x,y = newsgroups.data, newsgroups.target\n",
    "target_names = newsgroups.target_names\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "x_vect = vectorizer.fit_transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_vect,y,test_size = 0.2,random_state = 42)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentences:trump shot dead in his election ralley\n",
      "Prediction Category: rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "new_sentences = [input('Enter a sentence:')]\n",
    "new_x_vect = vectorizer.transform(new_sentences)\n",
    "predictions = model.predict(new_x_vect)\n",
    "\n",
    "for sentence, prediction in zip(new_sentences,predictions):\n",
    "    print(f'\\nsentences:{sentence}\\nPrediction Category: {target_names[prediction]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 2 sentences':1.00 \n"
     ]
    }
   ],
   "source": [
    "import spacy_legacy\n",
    "from spacy.cli import download\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "except OSError:\n",
    "    print('Model not found. Downloading...')\n",
    "    download('en_core_web_md')\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "word1 = nlp('Spiderman is Peter Parker.')\n",
    "word2 = nlp('Peter Parker is Spiderman.')\n",
    "\n",
    "similarity = word1.similarity(word2)\n",
    "print(f\"Similarity between 2 sentences':{similarity:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
